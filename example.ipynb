{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb61e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM,Dense,Activation, Bidirectional,Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee84a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('files.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafacb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=list(data.title.values)\n",
    "joinedtxt=\" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd04b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "partxt=joinedtxt[:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de72a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=RegexpTokenizer(r\"\\w+\")\n",
    "tokens=tokenizer.tokenize(partxt.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddb4a1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqtok=np.unique(tokens)\n",
    "unitokindex={token: idx for idx, token in enumerate(uniqtok)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d879f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwords=3\n",
    "inputwords=[]\n",
    "nextword=[]\n",
    "\n",
    "for i in range(len(tokens)-nwords):\n",
    "    inputwords.append(tokens [i:i + nwords])\n",
    "    nextword.append(tokens[i + nwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c45e5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.zeros((len(inputwords),nwords,len(uniqtok)),dtype=bool)\n",
    "y=np.zeros((len(nextword),len(uniqtok)),dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca73b0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i , words in enumerate(inputwords):\n",
    "    for j, word in enumerate(words):\n",
    "        x[i,j,unitokindex[word]]=1\n",
    "    y[i,unitokindex[nextword[i]]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c425c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(128, input_shape=(nwords,len(uniqtok)), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(len(uniqtok)))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbf84ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "147/147 [==============================] - 14s 64ms/step - loss: 6.4462 - accuracy: 0.0487\n",
      "Epoch 2/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 6.1093 - accuracy: 0.0641\n",
      "Epoch 3/30\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 5.8282 - accuracy: 0.0794\n",
      "Epoch 4/30\n",
      "147/147 [==============================] - 8s 56ms/step - loss: 5.5749 - accuracy: 0.1033\n",
      "Epoch 5/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 5.3569 - accuracy: 0.1177\n",
      "Epoch 6/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 5.1504 - accuracy: 0.1376\n",
      "Epoch 7/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 4.9445 - accuracy: 0.1525\n",
      "Epoch 8/30\n",
      "147/147 [==============================] - 8s 58ms/step - loss: 4.7273 - accuracy: 0.1750\n",
      "Epoch 9/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 4.5041 - accuracy: 0.1977\n",
      "Epoch 10/30\n",
      "147/147 [==============================] - 8s 58ms/step - loss: 4.2714 - accuracy: 0.2256\n",
      "Epoch 11/30\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 4.0173 - accuracy: 0.2598\n",
      "Epoch 12/30\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 3.7502 - accuracy: 0.2923\n",
      "Epoch 13/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 3.4754 - accuracy: 0.3266\n",
      "Epoch 14/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 3.1891 - accuracy: 0.3703\n",
      "Epoch 15/30\n",
      "147/147 [==============================] - 8s 58ms/step - loss: 2.9139 - accuracy: 0.4097\n",
      "Epoch 16/30\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 2.6457 - accuracy: 0.4565\n",
      "Epoch 17/30\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 2.3801 - accuracy: 0.5003\n",
      "Epoch 18/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 2.1427 - accuracy: 0.5501\n",
      "Epoch 19/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 1.9078 - accuracy: 0.5945\n",
      "Epoch 20/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 1.6906 - accuracy: 0.6433\n",
      "Epoch 21/30\n",
      "147/147 [==============================] - 9s 58ms/step - loss: 1.4927 - accuracy: 0.6870\n",
      "Epoch 22/30\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 1.3221 - accuracy: 0.7300\n",
      "Epoch 23/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 1.1614 - accuracy: 0.7702\n",
      "Epoch 24/30\n",
      "147/147 [==============================] - 10s 65ms/step - loss: 1.0325 - accuracy: 0.7995\n",
      "Epoch 25/30\n",
      "147/147 [==============================] - 9s 59ms/step - loss: 0.8979 - accuracy: 0.8288\n",
      "Epoch 26/30\n",
      "147/147 [==============================] - 8s 57ms/step - loss: 0.7983 - accuracy: 0.8484\n",
      "Epoch 27/30\n",
      "147/147 [==============================] - 8s 58ms/step - loss: 0.7046 - accuracy: 0.8663\n",
      "Epoch 28/30\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.6363 - accuracy: 0.8770\n",
      "Epoch 29/30\n",
      "147/147 [==============================] - 9s 61ms/step - loss: 0.5727 - accuracy: 0.8890\n",
      "Epoch 30/30\n",
      "147/147 [==============================] - 9s 60ms/step - loss: 0.5207 - accuracy: 0.8952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d7de4706d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=RMSprop(learning_rate=0.01),metrics=[\"accuracy\"])\n",
    "model.fit(x,y,batch_size=128,epochs=30,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ab90728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tak Dong Kyung\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b25d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0beb765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictnextword(input_text,nbest):\n",
    "    input_text=input_text.lower()\n",
    "    x=np.zeros((1,nwords,len(uniqtok)))\n",
    "    for i , word in enumerate(input_text.split()):\n",
    "        x[0,i,unitokindex[word]]=1\n",
    "    prediction= model.predict(x)[0]\n",
    "    return np.argpartition(prediction, -nbest)[-nbest:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dfe83f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the initials of the sentence \n",
      "how is this\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "['is', 'more', 'husband', 'attention', 'name', 'doubt', 'assistant', 'to']\n"
     ]
    }
   ],
   "source": [
    "str=input(\"Enter the initials of the sentence \\n\")\n",
    "possible=predictnextword(str,8)\n",
    "print([uniqtok[idx] for idx in possible])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
